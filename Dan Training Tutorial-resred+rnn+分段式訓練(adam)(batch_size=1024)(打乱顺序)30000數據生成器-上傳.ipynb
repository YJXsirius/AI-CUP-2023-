{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1f8ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Games: 100160, Total Moves: 22853380\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Input, Conv2D, ReLU, Flatten, Dense, Softmax,SimpleRNN\n",
    "from tensorflow.python.keras.layers import BatchNormalization,Activation,Add,Dropout,Reshape\n",
    "from tensorflow.python.keras.layers import GlobalAveragePooling2D,MaxPooling2D\n",
    "from tensorflow.python.keras.optimizers import adam_v2\n",
    "from tensorflow.keras.optimizers import SGD,Nadam\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping,ModelCheckpoint, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "tf.__version__\n",
    "df = open('./CSVs/dan_train.csv').read().splitlines()\n",
    "games = [i.split(',',2)[-1] for i in df]\n",
    "chars = 'abcdefghijklmnopqrs'\n",
    "coordinates = {k:v for v,k in enumerate(chars)}\n",
    "chartonumbers = {k:v for k,v in enumerate(chars)}\n",
    "def prepare_input(moves):\n",
    "    x = np.zeros((19,19,4))\n",
    "    for move in moves:       \n",
    "        color = move[0]\n",
    "        column = coordinates[move[2]]\n",
    "        row = coordinates[move[3]]\n",
    "        if color == 'B':\n",
    "            x[row,column,0] = 1\n",
    "            x[row,column,2] = 1\n",
    "        if color == 'W':\n",
    "            x[row,column,1] = 1\n",
    "            x[row,column,2] = 1\n",
    "    if moves:\n",
    "        last_move_column = coordinates[moves[-1][2]]\n",
    "        last_move_row = coordinates[moves[-1][3]]\n",
    "        x[row,column,3] = 1\n",
    "    x[:,:,2] = np.where(x[:,:,2] == 0, 1, 0)\n",
    "    return x\n",
    "\n",
    "def prepare_label(move):\n",
    "    column = coordinates[move[2]]\n",
    "    row = coordinates[move[3]]\n",
    "    return column*19+row\n",
    "\n",
    "#數據生成器:用來训练神经网络时逐批次地加载数据\n",
    "#---------------------------------------------------------------------------\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, games, batch_size):\n",
    "        self.games = games\n",
    "        self.batch_size = batch_size\n",
    "        self.index = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(len(game.split(',')) for game in self.games) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x_batch, y_batch = [], []\n",
    "        while len(x_batch) < self.batch_size:\n",
    "            game = self.games[self.index]\n",
    "            moves_list = game.split(',')\n",
    "            for count, move in enumerate(moves_list):\n",
    "                if len(x_batch) < self.batch_size:\n",
    "                    x_batch.append(prepare_input(moves_list[:count]))\n",
    "                    y_batch.append(prepare_label(moves_list[count]))\n",
    "                else:\n",
    "                    break  # Break when the batch is full\n",
    "            self.index = (self.index + 1) % len(self.games)  # Move to the next game\n",
    "        \n",
    "        x_batch = np.array(x_batch)\n",
    "        y_batch = np.array(y_batch)\n",
    "        y_batch_one_hot = tf.one_hot(y_batch, depth=19*19)\n",
    "        \n",
    "        return x_batch, y_batch_one_hot\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.games)\n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "# Check how many samples can be obtained\n",
    "n_games = 0\n",
    "n_moves = 0\n",
    "for game in games:\n",
    "    n_games += 1\n",
    "    moves_list = game.split(',')\n",
    "    for move in moves_list:\n",
    "        n_moves += 1\n",
    "print(f\"Total Games: {n_games}, Total Moves: {n_moves}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcf69ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 19, 19, 4)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 19, 19, 128)  4736        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 19, 19, 128)  512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 19, 19, 128)  0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 19, 19, 128)  147584      activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 19, 19, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 19, 19, 128)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 10, 10, 256)  295168      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 10, 10, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 10, 10, 256)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 10, 10, 256)  590080      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 10, 10, 256)  33024       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 10, 10, 256)  1024        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 10, 10, 256)  1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 10, 10, 256)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10, 10, 256)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 10, 10, 256)  0           activation_3[0][0]               \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10, 10, 256)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 10, 10, 256)  590080      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 10, 10, 256)  1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 10, 10, 256)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 10, 10, 256)  590080      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 10, 10, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 10, 10, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 10, 10, 256)  0           activation_6[0][0]               \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 5, 5, 512)    1180160     add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 5, 5, 512)    2048        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 5, 5, 512)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 5, 5, 512)    2359808     activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 5, 5, 512)    131584      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 5, 5, 512)    2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 5, 5, 512)    2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 5, 5, 512)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 5, 5, 512)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 5, 5, 512)    0           activation_8[0][0]               \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 5, 5, 512)    0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 5, 5, 512)    2359808     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 5, 5, 512)    2048        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 5, 5, 512)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 5, 5, 512)    2359808     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 5, 5, 512)    2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 5, 5, 512)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 5, 5, 512)    0           activation_11[0][0]              \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 361, 4)       0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 512)          0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "simple_rnn (SimpleRNN)          (None, 512)          264704      reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          262656      global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          262656      simple_rnn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 512)          0           dense_1[0][0]                    \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 600)          307800      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 600)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 400)          240400      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 400)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 361)          144761      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Softmax)               (None, 361)          0           dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,141,281\n",
      "Trainable params: 12,133,089\n",
      "Non-trainable params: 8,192\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def Conv_BN_Relu(filters, kernel_size, strides, input_layer):\n",
    "    x = Conv2D(filters, kernel_size, strides=strides, padding='same')(input_layer)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# ResNet18網絡\n",
    "def resiidual_a_or_b(input_x, filters, flag):\n",
    "    #殘差模塊a\n",
    "    if flag == 'a':\n",
    "        # 主路\n",
    "        x = Conv_BN_Relu(filters, (3, 3), 1, input_x)\n",
    "        x = Conv_BN_Relu(filters, (3, 3), 1, x)\n",
    "        # 输出\n",
    "        y = Add()([x, input_x])\n",
    "        return y\n",
    "\n",
    "    #殘差模塊b\n",
    "    elif flag == 'b':\n",
    "        # 主路\n",
    "        x = Conv_BN_Relu(filters, (3, 3), 2, input_x)\n",
    "        x = Conv_BN_Relu(filters, (3, 3), 1, x)\n",
    "        # 支路下採樣\n",
    "        input_x = Conv_BN_Relu(filters, (1, 1), 2, input_x)\n",
    "        # 输出\n",
    "        y = Add()([x, input_x])\n",
    "        return y\n",
    "def create_model():\n",
    "    # 第一层\n",
    "    input_layer = Input((19, 19, 4))\n",
    "    x = Conv_BN_Relu(128,(3, 3), 1, input_layer)\n",
    "    x = Conv_BN_Relu(128,(3, 3), 1, x)\n",
    "    \n",
    "    # conv2_x(\n",
    "    x = resiidual_a_or_b(x, 256, 'b')\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = resiidual_a_or_b(x, 256, 'a')\n",
    "    \n",
    "    #conv3_x\n",
    "    x = resiidual_a_or_b(x, 512, 'b')\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = resiidual_a_or_b(x, 512, 'a')\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    \n",
    "    # RNN层\n",
    "    rnn_units = 512  # 选择RNN层的单元数\n",
    "    x_rnn = Reshape(target_shape=(19 * 19, 4))(input_layer)  # 将输入形状转换为适合RNN的形状\n",
    "    x_rnn = SimpleRNN(units=rnn_units)(x_rnn)\n",
    "    x_rnn = Dense(512, activation='relu')(x_rnn)\n",
    "    \n",
    "\n",
    "    # 合并RNN输出和之前的模型输出\n",
    "    x = Dense(rnn_units)(x)\n",
    "    x = Add()([x, x_rnn])\n",
    "    \n",
    "    # 最后一层\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(600)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(400)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(361)(x)\n",
    "    y = Softmax(axis=-1)(x)\n",
    "    model = Model([input_layer], [y])\n",
    "\n",
    "    optimizer = 'adam'\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53cfe028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载模型: results/Dan_loss-accuracy_2.6725_0.4313_1_30000.h5\n",
      "开始训练: 1 - 30000\n",
      "Epoch 1/100\n",
      "6065/6065 [==============================] - 5539s 911ms/step - loss: 2.6795 - accuracy: 0.4356 - val_loss: 2.5507 - val_accuracy: 0.4467\n",
      "Epoch 2/100\n",
      "6065/6065 [==============================] - 5514s 909ms/step - loss: 2.6169 - accuracy: 0.4429 - val_loss: 2.4848 - val_accuracy: 0.4555\n",
      "Epoch 3/100\n",
      "6065/6065 [==============================] - 5551s 915ms/step - loss: 2.5524 - accuracy: 0.4515 - val_loss: 2.4468 - val_accuracy: 0.4584\n",
      "Epoch 4/100\n",
      "6065/6065 [==============================] - 5519s 910ms/step - loss: 2.5035 - accuracy: 0.4583 - val_loss: 2.4269 - val_accuracy: 0.4628\n",
      "Epoch 5/100\n",
      "6065/6065 [==============================] - 5515s 909ms/step - loss: 2.4619 - accuracy: 0.4634 - val_loss: 2.4082 - val_accuracy: 0.4653\n",
      "Epoch 6/100\n",
      "6065/6065 [==============================] - 5505s 908ms/step - loss: 2.4269 - accuracy: 0.4687 - val_loss: 2.4001 - val_accuracy: 0.4683\n",
      "Epoch 7/100\n",
      "6065/6065 [==============================] - 5509s 908ms/step - loss: 2.3947 - accuracy: 0.4731 - val_loss: 2.3956 - val_accuracy: 0.4688\n",
      "Epoch 8/100\n",
      "6065/6065 [==============================] - 5510s 908ms/step - loss: 2.3707 - accuracy: 0.4766 - val_loss: 2.3996 - val_accuracy: 0.4698\n",
      "Epoch 9/100\n",
      "6065/6065 [==============================] - 5517s 910ms/step - loss: 2.3437 - accuracy: 0.4806 - val_loss: 2.3816 - val_accuracy: 0.4681\n",
      "Epoch 10/100\n",
      "6065/6065 [==============================] - 5515s 909ms/step - loss: 2.3192 - accuracy: 0.4843 - val_loss: 2.3858 - val_accuracy: 0.4694\n",
      "Epoch 11/100\n",
      "6065/6065 [==============================] - 5511s 909ms/step - loss: 2.3022 - accuracy: 0.4875 - val_loss: 2.3831 - val_accuracy: 0.4685\n",
      "Epoch 12/100\n",
      "6065/6065 [==============================] - 5523s 911ms/step - loss: 2.2789 - accuracy: 0.4906 - val_loss: 2.3901 - val_accuracy: 0.4698\n",
      "加载模型: results/Dan_loss-accuracy_2.3816_0.4681_1_30000.h5\n",
      "开始训练: 30001 - 60000\n",
      "Epoch 1/100\n",
      "5982/5982 [==============================] - 5451s 911ms/step - loss: 2.5234 - accuracy: 0.4549 - val_loss: 2.3459 - val_accuracy: 0.4742\n",
      "Epoch 2/100\n",
      "5982/5982 [==============================] - 5463s 913ms/step - loss: 2.4601 - accuracy: 0.4639 - val_loss: 2.3334 - val_accuracy: 0.4759\n",
      "Epoch 3/100\n",
      "5982/5982 [==============================] - 5439s 909ms/step - loss: 2.4178 - accuracy: 0.4696 - val_loss: 2.3226 - val_accuracy: 0.4782\n",
      "Epoch 4/100\n",
      "5982/5982 [==============================] - 5453s 912ms/step - loss: 2.3846 - accuracy: 0.4744 - val_loss: 2.3218 - val_accuracy: 0.4765\n",
      "Epoch 5/100\n",
      "5982/5982 [==============================] - 5444s 910ms/step - loss: 2.3542 - accuracy: 0.4789 - val_loss: 2.3171 - val_accuracy: 0.4787\n",
      "Epoch 6/100\n",
      "5982/5982 [==============================] - 5440s 909ms/step - loss: 2.3296 - accuracy: 0.4825 - val_loss: 2.3252 - val_accuracy: 0.4773\n",
      "Epoch 7/100\n",
      "5982/5982 [==============================] - 5441s 910ms/step - loss: 2.3049 - accuracy: 0.4863 - val_loss: 2.3297 - val_accuracy: 0.4765\n",
      "Epoch 8/100\n",
      "5982/5982 [==============================] - 5441s 910ms/step - loss: 2.2850 - accuracy: 0.4895 - val_loss: 2.3414 - val_accuracy: 0.4788\n",
      "加载模型: results/Dan_loss-accuracy_2.3171_0.4787_30001_60000.h5\n",
      "开始训练: 60001 - 110000\n",
      "Epoch 1/100\n",
      "8028/8028 [==============================] - 7301s 909ms/step - loss: 2.4482 - accuracy: 0.4654 - val_loss: 2.2687 - val_accuracy: 0.4851\n",
      "Epoch 2/100\n",
      "8028/8028 [==============================] - 7300s 909ms/step - loss: 2.3962 - accuracy: 0.4726 - val_loss: 2.2559 - val_accuracy: 0.4873\n",
      "Epoch 3/100\n",
      "8028/8028 [==============================] - 7304s 910ms/step - loss: 2.3601 - accuracy: 0.4776 - val_loss: 2.2585 - val_accuracy: 0.4857\n",
      "Epoch 4/100\n",
      "8028/8028 [==============================] - 7307s 910ms/step - loss: 2.3315 - accuracy: 0.4819 - val_loss: 2.2397 - val_accuracy: 0.4887\n",
      "Epoch 5/100\n",
      "8028/8028 [==============================] - 11175s 1s/step - loss: 2.3066 - accuracy: 0.4855 - val_loss: 2.2467 - val_accuracy: 0.4884\n",
      "Epoch 6/100\n",
      " 155/8028 [..............................] - ETA: 4:12:33 - loss: 2.2593 - accuracy: 0.4917"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6944\\2702023077.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     )\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = 1\n",
    "end = 30000\n",
    "batch_size = 1024\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "\n",
    "'''\n",
    "這裡內容為訓練中斷,需要重新讀取權重,繼續訓練\n",
    "# 尋找所有文件\n",
    "saved_models = os.listdir('./results/Dan/')\n",
    "# 找到具有最低验证损失的模型文件\n",
    "best_model = min(saved_models, key=lambda x: float(x.split('_')[2]) if x.startswith('Dan_loss-accuracy') else float('inf'))\n",
    "# 构建最佳模型的路径\n",
    "best_model_path = os.path.join('./results/Dan/', best_model)\n",
    "print(\"加载模型:\",best_model_path)\n",
    "# 加载最佳模型的权重\n",
    "model.load_weights(best_model_path)\n",
    "''' \n",
    "\n",
    "# 定义 EarlyStopping 回调 :回调参数\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "for i in range(3):\n",
    "    print(\"开始训练:\", start, \"-\", end)\n",
    "    \n",
    "    # 定义 ModelCheckpoint 回调 :回调保存\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        f'./results/Dan/Dan_loss-accuracy_{{val_loss:.4f}}_{{val_accuracy:.4f}}_{start}_{end}.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True)\n",
    "    \n",
    "    # 將數據分成訓練和驗證集\n",
    "    games_train, games_val = train_test_split(games[start:end], test_size=0.10,random_state=42)\n",
    "\n",
    "    # 創建數據生成器實例\n",
    "    train_generator = DataGenerator(games_train, batch_size)\n",
    "    val_generator = DataGenerator(games_val, batch_size) \n",
    "    \n",
    "\n",
    "    \n",
    "    #用数据生成器进行训练\n",
    "    history = model.fit(\n",
    "        x=train_generator,\n",
    "        epochs=100,\n",
    "        validation_data=val_generator, \n",
    "        callbacks=[checkpoint, early_stopping],\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # 尋找所有文件\n",
    "    saved_models = os.listdir('./results/Dan/')\n",
    "    # 找到具有最低验证损失的模型文件\n",
    "    best_model = min(saved_models, key=lambda x: float(x.split('_')[2]) if x.startswith('Dan_loss-accuracy') else float('inf'))\n",
    "    # 构建最佳模型的路径\n",
    "    best_model_path = os.path.join('./results/Dan/', best_model)\n",
    "    print(\"加载模型:\",best_model_path)\n",
    "    # 加载最佳模型的权重\n",
    "    model.load_weights(best_model_path)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #將每個 epoch 的值添加到列表中\n",
    "    train_losses.extend(history.history['loss'])\n",
    "    val_losses.extend(history.history['val_loss'])\n",
    "    train_accuracy.extend(history.history['accuracy'])\n",
    "    val_accuracy.extend(history.history['val_accuracy'])\n",
    "    \n",
    "    \n",
    "    start=start+30000;\n",
    "    end=end+30000;\n",
    "    if (end==90000):\n",
    "        end=110000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3211d17",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23c455f",
   "metadata": {},
   "source": [
    "# 以下內容為訓練中斷,需要重新讀取權重,繼續訓練的重複內容,無需進行執行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14340beb",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2e9d507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载模型: results/Dan_loss-accuracy_2.2397_0.4887_60001_110000.h5\n",
      "开始训练: 60001 - 110000\n",
      "Epoch 1/100\n",
      "8028/8028 [==============================] - 7354s 915ms/step - loss: 2.2926 - accuracy: 0.4876 - val_loss: 2.2528 - val_accuracy: 0.4880\n",
      "Epoch 2/100\n",
      "8028/8028 [==============================] - 7297s 909ms/step - loss: 2.2837 - accuracy: 0.4892 - val_loss: 2.2444 - val_accuracy: 0.4890\n",
      "Epoch 3/100\n",
      "8028/8028 [==============================] - 7301s 909ms/step - loss: 2.2634 - accuracy: 0.4919 - val_loss: 2.2524 - val_accuracy: 0.4889\n",
      "Epoch 4/100\n",
      "8028/8028 [==============================] - 7297s 909ms/step - loss: 2.2456 - accuracy: 0.4948 - val_loss: 2.2448 - val_accuracy: 0.4890\n",
      "Epoch 5/100\n",
      "8028/8028 [==============================] - 7287s 908ms/step - loss: 2.1517 - accuracy: 0.5083 - val_loss: 2.1973 - val_accuracy: 0.4946\n",
      "Epoch 6/100\n",
      "8028/8028 [==============================] - 7307s 910ms/step - loss: 2.1171 - accuracy: 0.5130 - val_loss: 2.1961 - val_accuracy: 0.4954\n",
      "Epoch 7/100\n",
      "8028/8028 [==============================] - 7330s 913ms/step - loss: 2.1036 - accuracy: 0.5149 - val_loss: 2.1950 - val_accuracy: 0.4961\n",
      "Epoch 8/100\n",
      "8028/8028 [==============================] - 7305s 910ms/step - loss: 2.0964 - accuracy: 0.5163 - val_loss: 2.2004 - val_accuracy: 0.4947\n",
      "Epoch 9/100\n",
      "8028/8028 [==============================] - 7299s 909ms/step - loss: 2.0837 - accuracy: 0.5186 - val_loss: 2.2003 - val_accuracy: 0.4949\n",
      "Epoch 10/100\n",
      "8028/8028 [==============================] - 7303s 910ms/step - loss: 2.0647 - accuracy: 0.5215 - val_loss: 2.1927 - val_accuracy: 0.4955\n",
      "Epoch 11/100\n",
      "8028/8028 [==============================] - 7305s 910ms/step - loss: 2.0565 - accuracy: 0.5225 - val_loss: 2.1984 - val_accuracy: 0.4948\n",
      "Epoch 12/100\n",
      "8028/8028 [==============================] - 7307s 910ms/step - loss: 2.0546 - accuracy: 0.5230 - val_loss: 2.1903 - val_accuracy: 0.4957\n",
      "Epoch 13/100\n",
      "8028/8028 [==============================] - 7306s 910ms/step - loss: 2.0507 - accuracy: 0.5234 - val_loss: 2.1943 - val_accuracy: 0.4961\n",
      "Epoch 14/100\n",
      "8028/8028 [==============================] - 7294s 909ms/step - loss: 2.0500 - accuracy: 0.5235 - val_loss: 2.1962 - val_accuracy: 0.4948\n",
      "Epoch 15/100\n",
      "8028/8028 [==============================] - 7332s 913ms/step - loss: 2.0453 - accuracy: 0.5244 - val_loss: 2.1905 - val_accuracy: 0.4956\n",
      "Epoch 16/100\n",
      "8028/8028 [==============================] - 7562s 942ms/step - loss: 2.0445 - accuracy: 0.5244 - val_loss: 2.1904 - val_accuracy: 0.4960\n",
      "Epoch 17/100\n",
      "8028/8028 [==============================] - 7447s 928ms/step - loss: 2.0423 - accuracy: 0.5247 - val_loss: 2.1907 - val_accuracy: 0.4957\n",
      "Epoch 18/100\n",
      "8028/8028 [==============================] - 7374s 919ms/step - loss: 2.0459 - accuracy: 0.5242 - val_loss: 2.1911 - val_accuracy: 0.4959\n",
      "加载模型: results/Dan_loss-accuracy_2.1903_0.4957_60001_110000.h5\n",
      "开始训练: 90001 - 140000\n",
      "Epoch 1/100\n",
      "2019/2019 [==============================] - 1856s 919ms/step - loss: 2.0725 - accuracy: 0.5198 - val_loss: 1.8608 - val_accuracy: 0.5506\n",
      "Epoch 2/100\n",
      "2019/2019 [==============================] - 1856s 919ms/step - loss: 2.0719 - accuracy: 0.5198 - val_loss: 1.8595 - val_accuracy: 0.5504\n",
      "Epoch 3/100\n",
      "2019/2019 [==============================] - 1858s 920ms/step - loss: 2.0727 - accuracy: 0.5195 - val_loss: 1.8568 - val_accuracy: 0.5508\n",
      "Epoch 4/100\n",
      "2019/2019 [==============================] - 1859s 921ms/step - loss: 2.0719 - accuracy: 0.5197 - val_loss: 1.8540 - val_accuracy: 0.5516\n",
      "Epoch 5/100\n",
      "2019/2019 [==============================] - 1856s 919ms/step - loss: 2.0709 - accuracy: 0.5201 - val_loss: 1.8547 - val_accuracy: 0.5512\n",
      "Epoch 6/100\n",
      "2019/2019 [==============================] - 1857s 920ms/step - loss: 2.0736 - accuracy: 0.5195 - val_loss: 1.8576 - val_accuracy: 0.5506\n",
      "Epoch 7/100\n",
      "2019/2019 [==============================] - 1858s 920ms/step - loss: 2.0705 - accuracy: 0.5201 - val_loss: 1.8531 - val_accuracy: 0.5516\n",
      "Epoch 8/100\n",
      "2019/2019 [==============================] - 1856s 919ms/step - loss: 2.0712 - accuracy: 0.5202 - val_loss: 1.8584 - val_accuracy: 0.5505\n",
      "Epoch 9/100\n",
      "2019/2019 [==============================] - 1856s 919ms/step - loss: 2.0755 - accuracy: 0.5195 - val_loss: 1.8533 - val_accuracy: 0.5511\n",
      "Epoch 10/100\n",
      "2019/2019 [==============================] - 1852s 917ms/step - loss: 2.0719 - accuracy: 0.5196 - val_loss: 1.8611 - val_accuracy: 0.5501\n",
      "Epoch 11/100\n",
      "2019/2019 [==============================] - 1856s 919ms/step - loss: 2.0708 - accuracy: 0.5206 - val_loss: 1.8557 - val_accuracy: 0.5515\n",
      "Epoch 12/100\n",
      "2019/2019 [==============================] - 1858s 920ms/step - loss: 2.0713 - accuracy: 0.5202 - val_loss: 1.8483 - val_accuracy: 0.5526\n",
      "Epoch 13/100\n",
      "2019/2019 [==============================] - 1858s 920ms/step - loss: 2.0700 - accuracy: 0.5200 - val_loss: 1.8574 - val_accuracy: 0.5505\n",
      "Epoch 14/100\n",
      "2019/2019 [==============================] - 1857s 920ms/step - loss: 2.0700 - accuracy: 0.5204 - val_loss: 1.8525 - val_accuracy: 0.5510\n",
      "Epoch 15/100\n",
      "2019/2019 [==============================] - 1855s 919ms/step - loss: 2.0696 - accuracy: 0.5201 - val_loss: 1.8563 - val_accuracy: 0.5507\n",
      "Epoch 16/100\n",
      "2019/2019 [==============================] - 1860s 921ms/step - loss: 2.0725 - accuracy: 0.5198 - val_loss: 1.8573 - val_accuracy: 0.5512\n",
      "Epoch 17/100\n",
      "2019/2019 [==============================] - 1860s 921ms/step - loss: 2.0704 - accuracy: 0.5204 - val_loss: 1.8554 - val_accuracy: 0.5511\n",
      "Epoch 18/100\n",
      "2019/2019 [==============================] - 1862s 922ms/step - loss: 2.0720 - accuracy: 0.5201 - val_loss: 1.8535 - val_accuracy: 0.5508\n",
      "加载模型: results/Dan_loss-accuracy_1.8483_0.5526_90001_140000.h5\n",
      "开始训练: 120001 - 170000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4760\\4120086498.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m# 將數據分成訓練和驗證集\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mgames_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgames_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m# 創建數據生成器實例\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2420\u001b[0m     n_train, n_test = _validate_shuffle_split(\n\u001b[1;32m-> 2421\u001b[1;33m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2422\u001b[0m     )\n\u001b[0;32m   2423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2099\u001b[0m             \u001b[1;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2100\u001b[0m             \u001b[1;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2101\u001b[1;33m             \u001b[1;34m\"aforementioned parameters.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2102\u001b[0m         )\n\u001b[0;32m   2103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "'''\n",
    "start = 60001\n",
    "end = 110000\n",
    "batch_size = 1024\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "\n",
    "\n",
    "# 尋找所有文件\n",
    "saved_models = os.listdir('./results/Dan/')\n",
    "# 找到具有最低验证损失的模型文件\n",
    "best_model = min(saved_models, key=lambda x: float(x.split('_')[2]) if x.startswith('Dan_loss-accuracy') else float('inf'))\n",
    "# 构建最佳模型的路径\n",
    "best_model_path = os.path.join('./results/Dan/', best_model)\n",
    "print(\"加载模型:\",best_model_path)\n",
    "# 加载最佳模型的权重\n",
    "model.load_weights(best_model_path)\n",
    "\n",
    "# 定义 EarlyStopping 回调 :回调参数\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "\n",
    "for i in range(3):\n",
    "    print(\"开始训练:\", start, \"-\", end)\n",
    "    \n",
    "    # 定义 ModelCheckpoint 回调 :回调保存\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        f'./results/Dan/Dan_loss-accuracy_{{val_loss:.4f}}_{{val_accuracy:.4f}}_{start}_{end}.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True)\n",
    "    \n",
    "    # 將數據分成訓練和驗證集\n",
    "    games_train, games_val = train_test_split(games[start:end], test_size=0.10,random_state=42)\n",
    "\n",
    "    # 創建數據生成器實例\n",
    "    train_generator = DataGenerator(games_train, batch_size)\n",
    "    val_generator = DataGenerator(games_val, batch_size) \n",
    "    \n",
    "\n",
    "    \n",
    "    #用数据生成器进行训练\n",
    "    history = model.fit(\n",
    "        x=train_generator,\n",
    "        epochs=100,\n",
    "        validation_data=val_generator, \n",
    "        callbacks=[checkpoint, early_stopping,\n",
    "                  ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-7)],\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # 尋找所有文件\n",
    "    saved_models = os.listdir('./results/Dan/')\n",
    "    # 找到具有最低验证损失的模型文件\n",
    "    best_model = min(saved_models, key=lambda x: float(x.split('_')[2]) if x.startswith('Dan_loss-accuracy') else float('inf'))\n",
    "    # 构建最佳模型的路径\n",
    "    best_model_path = os.path.join('./results/Dan/', best_model)\n",
    "    print(\"加载模型:\",best_model_path)\n",
    "    # 加载最佳模型的权重\n",
    "    model.load_weights(best_model_path)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #將每個 epoch 的值添加到列表中\n",
    "    train_losses.extend(history.history['loss'])\n",
    "    val_losses.extend(history.history['val_loss'])\n",
    "    train_accuracy.extend(history.history['accuracy'])\n",
    "    val_accuracy.extend(history.history['val_accuracy'])\n",
    "    \n",
    "    \n",
    "    start=start+30000;\n",
    "    end=end+30000;\n",
    "    if (end==90000):\n",
    "        end=110000\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
