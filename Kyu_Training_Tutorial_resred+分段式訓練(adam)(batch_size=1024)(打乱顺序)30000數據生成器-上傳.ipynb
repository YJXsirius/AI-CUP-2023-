{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "0vXliOUsxEd7",
    "outputId": "479e822a-64db-43d2-c4f0-3c07a11305c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, Flatten, Dense, Softmax\n",
    "from tensorflow.keras.layers import BatchNormalization,Activation,Add,Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D,MaxPooling2D\n",
    "from tensorflow.python.keras.optimizers import adam_v2\n",
    "from tensorflow.keras.optimizers import SGD,Nadam\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping,ModelCheckpoint, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "25abE5-Uwbl0",
    "outputId": "6e2bc6e6-c7d5-43dc-e447-fb337d436694"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Games: 118500, Total Moves: 27135638\n"
     ]
    }
   ],
   "source": [
    "df = open('./CSVs/kyu_train.csv').read().splitlines()\n",
    "games = [i.split(',',2)[-1] for i in df]\n",
    "chars = 'abcdefghijklmnopqrs'\n",
    "coordinates = {k:v for v,k in enumerate(chars)}\n",
    "chartonumbers = {k:v for k,v in enumerate(chars)}\n",
    "def prepare_input(moves):\n",
    "    x = np.zeros((19,19,4))\n",
    "    for move in moves:\n",
    "        color = move[0]\n",
    "        column = coordinates[move[2]]\n",
    "        row = coordinates[move[3]]\n",
    "        if color == 'B':\n",
    "            x[row,column,0] = 1\n",
    "            x[row,column,2] = 1\n",
    "        if color == 'W':\n",
    "            x[row,column,1] = 1\n",
    "            x[row,column,2] = 1\n",
    "    if moves:\n",
    "        last_move_column = coordinates[moves[-1][2]]\n",
    "        last_move_row = coordinates[moves[-1][3]]\n",
    "        x[row,column,3] = 1\n",
    "    x[:,:,2] = np.where(x[:,:,2] == 0, 1, 0)\n",
    "    return x\n",
    "\n",
    "def prepare_label(move):\n",
    "    column = coordinates[move[2]]\n",
    "    row = coordinates[move[3]]\n",
    "    return column*19+row\n",
    "\n",
    "#數據生成器:用來训练神经网络时逐批次地加载数据\n",
    "#---------------------------------------------------------------------------\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, games, batch_size):\n",
    "        self.games = games\n",
    "        self.batch_size = batch_size\n",
    "        self.index = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(len(game.split(',')) for game in self.games) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x_batch, y_batch = [], []\n",
    "        while len(x_batch) < self.batch_size:\n",
    "            game = self.games[self.index]\n",
    "            moves_list = game.split(',')\n",
    "            for count, move in enumerate(moves_list):\n",
    "                if len(x_batch) < self.batch_size:\n",
    "                    x_batch.append(prepare_input(moves_list[:count]))\n",
    "                    y_batch.append(prepare_label(moves_list[count]))\n",
    "                else:\n",
    "                    break  # Break when the batch is full\n",
    "            self.index = (self.index + 1) % len(self.games)  # Move to the next game\n",
    "\n",
    "        x_batch = np.array(x_batch)\n",
    "        y_batch = np.array(y_batch)\n",
    "        y_batch_one_hot = tf.one_hot(y_batch, depth=19*19)\n",
    "\n",
    "        return x_batch, y_batch_one_hot\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.games)\n",
    "#---------------------------------------------------------------------------\n",
    "\n",
    "# Check how many samples can be obtained\n",
    "n_games = 0\n",
    "n_moves = 0\n",
    "for game in games:\n",
    "    n_games += 1\n",
    "    moves_list = game.split(',')\n",
    "    for move in moves_list:\n",
    "        n_moves += 1\n",
    "print(f\"Total Games: {n_games}, Total Moves: {n_moves}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "czQ4sZaRwfLy",
    "outputId": "f7ff0fb9-f27d-47fe-f40f-467b28fd20bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 19, 19, 4)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 19, 19, 128)  4736        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 19, 19, 128)  512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 19, 19, 128)  0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 19, 19, 128)  147584      activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 19, 19, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 19, 19, 128)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 10, 10, 256)  295168      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 10, 10, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 10, 10, 256)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 10, 10, 256)  590080      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 10, 10, 256)  33024       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 10, 10, 256)  1024        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 10, 10, 256)  1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 10, 10, 256)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10, 10, 256)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 10, 10, 256)  0           activation_3[0][0]               \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10, 10, 256)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 10, 10, 256)  590080      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 10, 10, 256)  1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 10, 10, 256)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 10, 10, 256)  590080      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 10, 10, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 10, 10, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 10, 10, 256)  0           activation_6[0][0]               \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 5, 5, 512)    1180160     add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 5, 5, 512)    2048        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 5, 5, 512)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 5, 5, 512)    2359808     activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 5, 5, 512)    131584      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 5, 5, 512)    2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 5, 5, 512)    2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 5, 5, 512)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 5, 5, 512)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 5, 5, 512)    0           activation_8[0][0]               \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 5, 5, 512)    0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 5, 5, 512)    2359808     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 5, 5, 512)    2048        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 5, 5, 512)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 5, 5, 512)    2359808     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 5, 5, 512)    2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 5, 5, 512)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 5, 5, 512)    0           activation_11[0][0]              \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 512)          0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 600)          307800      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 600)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 400)          240400      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 400)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 361)          144761      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Softmax)               (None, 361)          0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 11,351,265\n",
      "Trainable params: 11,343,073\n",
      "Non-trainable params: 8,192\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def Conv_BN_Relu(filters, kernel_size, strides, input_layer):\n",
    "    x = Conv2D(filters, kernel_size, strides=strides, padding='same')(input_layer)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# ResNet18网络对应的残差模块a和残差模块b\n",
    "def resiidual_a_or_b(input_x, filters, flag):\n",
    "    #残差模块a\n",
    "    if flag == 'a':\n",
    "        # 主路\n",
    "        x = Conv_BN_Relu(filters, (3, 3), 1, input_x)\n",
    "        x = Conv_BN_Relu(filters, (3, 3), 1, x)\n",
    "        # 输出\n",
    "        y = Add()([x, input_x])\n",
    "        return y\n",
    "    #残差模块b\n",
    "    elif flag == 'b':\n",
    "        # 主路\n",
    "        x = Conv_BN_Relu(filters, (3, 3), 2, input_x)\n",
    "        x = Conv_BN_Relu(filters, (3, 3), 1, x)\n",
    "        # 支路下采样\n",
    "        input_x = Conv_BN_Relu(filters, (1, 1), 2, input_x)\n",
    "        # 输出\n",
    "        y = Add()([x, input_x])\n",
    "        return y\n",
    "def create_model():\n",
    "    # 第一层\n",
    "    input_layer = Input((19, 19, 4))\n",
    "    x = Conv_BN_Relu(128,(3, 3), 1, input_layer)\n",
    "    x = Conv_BN_Relu(128,(3, 3), 1, x)\n",
    "    \n",
    "    # conv2_x\n",
    "    x = resiidual_a_or_b(x, 256, 'b')\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = resiidual_a_or_b(x, 256, 'a')\n",
    "\n",
    "    #conv3_x\n",
    "    x = resiidual_a_or_b(x, 512, 'b')\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = resiidual_a_or_b(x, 512, 'a')\n",
    "\n",
    "\n",
    "    # 最后一层\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(600)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(400)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(361)(x)\n",
    "    y = Softmax(axis=-1)(x)\n",
    "    model = Model([input_layer], [y])\n",
    "\n",
    "\n",
    "    optimizer = 'adam'\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z-Itxk5owhTA",
    "outputId": "75b023c8-0638-4e92-abca-3eb3b9daf2b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练: 1 - 30000\n",
      "Epoch 1/100\n",
      "6056/6056 [==============================] - 2671s 440ms/step - loss: 3.7057 - accuracy: 0.2702 - val_loss: 2.5967 - val_accuracy: 0.4494\n",
      "Epoch 2/100\n",
      "6056/6056 [==============================] - 2663s 440ms/step - loss: 2.6654 - accuracy: 0.4442 - val_loss: 2.4632 - val_accuracy: 0.4650\n",
      "Epoch 3/100\n",
      "6056/6056 [==============================] - 2659s 439ms/step - loss: 2.5245 - accuracy: 0.4607 - val_loss: 2.3416 - val_accuracy: 0.4776\n",
      "Epoch 4/100\n",
      "6056/6056 [==============================] - 2658s 439ms/step - loss: 2.4433 - accuracy: 0.4712 - val_loss: 2.3015 - val_accuracy: 0.4871\n",
      "Epoch 5/100\n",
      "6056/6056 [==============================] - 2660s 439ms/step - loss: 2.3876 - accuracy: 0.4784 - val_loss: 2.2739 - val_accuracy: 0.4891\n",
      "Epoch 6/100\n",
      "6056/6056 [==============================] - 2661s 439ms/step - loss: 2.3434 - accuracy: 0.4842 - val_loss: 2.2483 - val_accuracy: 0.4911\n",
      "Epoch 7/100\n",
      "6056/6056 [==============================] - 2660s 439ms/step - loss: 2.3005 - accuracy: 0.4903 - val_loss: 2.2387 - val_accuracy: 0.4934\n",
      "Epoch 8/100\n",
      "6056/6056 [==============================] - 2659s 439ms/step - loss: 2.2699 - accuracy: 0.4944 - val_loss: 2.2354 - val_accuracy: 0.4939\n",
      "Epoch 9/100\n",
      "6056/6056 [==============================] - 2660s 439ms/step - loss: 2.2433 - accuracy: 0.4989 - val_loss: 2.2513 - val_accuracy: 0.4936\n",
      "Epoch 10/100\n",
      "6056/6056 [==============================] - 2660s 439ms/step - loss: 2.2188 - accuracy: 0.5023 - val_loss: 2.2417 - val_accuracy: 0.4947\n",
      "Epoch 11/100\n",
      "6056/6056 [==============================] - 2660s 439ms/step - loss: 2.1932 - accuracy: 0.5064 - val_loss: 2.2291 - val_accuracy: 0.4960\n",
      "Epoch 12/100\n",
      "6056/6056 [==============================] - 2660s 439ms/step - loss: 2.1733 - accuracy: 0.5093 - val_loss: 2.2287 - val_accuracy: 0.4953\n",
      "Epoch 13/100\n",
      "6056/6056 [==============================] - 2660s 439ms/step - loss: 2.1537 - accuracy: 0.5118 - val_loss: 2.2178 - val_accuracy: 0.4970\n",
      "Epoch 14/100\n",
      "6056/6056 [==============================] - 2659s 439ms/step - loss: 2.1369 - accuracy: 0.5146 - val_loss: 2.2291 - val_accuracy: 0.4961\n",
      "Epoch 15/100\n",
      "6056/6056 [==============================] - 2659s 439ms/step - loss: 2.1169 - accuracy: 0.5182 - val_loss: 2.2284 - val_accuracy: 0.4974\n",
      "Epoch 16/100\n",
      "6056/6056 [==============================] - 2658s 439ms/step - loss: 2.1023 - accuracy: 0.5206 - val_loss: 2.2317 - val_accuracy: 0.4964\n",
      "Epoch 17/100\n",
      "6056/6056 [==============================] - 2658s 439ms/step - loss: 2.0841 - accuracy: 0.5232 - val_loss: 2.2228 - val_accuracy: 0.4969\n",
      "Epoch 18/100\n",
      "6056/6056 [==============================] - 2660s 439ms/step - loss: 2.0732 - accuracy: 0.5250 - val_loss: 2.2354 - val_accuracy: 0.4962\n",
      "Epoch 19/100\n",
      "6056/6056 [==============================] - 2661s 439ms/step - loss: 2.0576 - accuracy: 0.5280 - val_loss: 2.2375 - val_accuracy: 0.4938\n",
      "Epoch 20/100\n",
      "6056/6056 [==============================] - 2660s 439ms/step - loss: 2.0435 - accuracy: 0.5302 - val_loss: 2.2394 - val_accuracy: 0.4960\n",
      "Epoch 21/100\n",
      "6056/6056 [==============================] - 2660s 439ms/step - loss: 2.0379 - accuracy: 0.5314 - val_loss: 2.2507 - val_accuracy: 0.4958\n",
      "Epoch 22/100\n",
      "6056/6056 [==============================] - 2663s 440ms/step - loss: 2.0251 - accuracy: 0.5334 - val_loss: 2.2477 - val_accuracy: 0.4964\n",
      "Epoch 23/100\n",
      "6056/6056 [==============================] - 2659s 439ms/step - loss: 2.0122 - accuracy: 0.5357 - val_loss: 2.2585 - val_accuracy: 0.4934\n",
      "加载模型: results/kyu_loss-accuracy_2.2178_0.4970_1_30000.h5\n",
      "开始训练: 30001 - 60000\n",
      "Epoch 1/100\n",
      "6049/6049 [==============================] - 2655s 439ms/step - loss: 2.3527 - accuracy: 0.4830 - val_loss: 2.1762 - val_accuracy: 0.5009\n",
      "Epoch 2/100\n",
      "6049/6049 [==============================] - 2654s 439ms/step - loss: 2.2949 - accuracy: 0.4904 - val_loss: 2.1673 - val_accuracy: 0.5033\n",
      "Epoch 3/100\n",
      "6049/6049 [==============================] - 2654s 439ms/step - loss: 2.2546 - accuracy: 0.4963 - val_loss: 2.1626 - val_accuracy: 0.5022\n",
      "Epoch 4/100\n",
      "6049/6049 [==============================] - 2663s 440ms/step - loss: 2.2229 - accuracy: 0.5007 - val_loss: 2.1630 - val_accuracy: 0.5024\n",
      "Epoch 5/100\n",
      "6049/6049 [==============================] - 2652s 438ms/step - loss: 2.1992 - accuracy: 0.5044 - val_loss: 2.1650 - val_accuracy: 0.5029\n",
      "Epoch 6/100\n",
      "6049/6049 [==============================] - 2651s 438ms/step - loss: 2.1721 - accuracy: 0.5088 - val_loss: 2.1468 - val_accuracy: 0.5048\n",
      "Epoch 7/100\n",
      "6049/6049 [==============================] - 2654s 439ms/step - loss: 2.1510 - accuracy: 0.5117 - val_loss: 2.1644 - val_accuracy: 0.5027\n",
      "Epoch 8/100\n",
      "6049/6049 [==============================] - 2663s 440ms/step - loss: 2.1306 - accuracy: 0.5150 - val_loss: 2.1618 - val_accuracy: 0.5035\n",
      "Epoch 9/100\n",
      "6049/6049 [==============================] - 3433s 568ms/step - loss: 2.1140 - accuracy: 0.5173 - val_loss: 2.1710 - val_accuracy: 0.5032\n",
      "Epoch 10/100\n",
      "6049/6049 [==============================] - 2673s 442ms/step - loss: 2.0962 - accuracy: 0.5201 - val_loss: 2.1692 - val_accuracy: 0.5036\n",
      "Epoch 11/100\n",
      "6049/6049 [==============================] - 2668s 441ms/step - loss: 2.0797 - accuracy: 0.5228 - val_loss: 2.1767 - val_accuracy: 0.5009\n",
      "Epoch 12/100\n",
      "6049/6049 [==============================] - 2722s 450ms/step - loss: 2.0655 - accuracy: 0.5250 - val_loss: 2.1744 - val_accuracy: 0.5020\n",
      "Epoch 13/100\n",
      "6049/6049 [==============================] - 2720s 450ms/step - loss: 2.0507 - accuracy: 0.5279 - val_loss: 2.1910 - val_accuracy: 0.5021\n",
      "Epoch 14/100\n",
      "6049/6049 [==============================] - 2715s 449ms/step - loss: 2.0367 - accuracy: 0.5301 - val_loss: 2.1904 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "6049/6049 [==============================] - 2681s 443ms/step - loss: 2.0256 - accuracy: 0.5320 - val_loss: 2.1914 - val_accuracy: 0.5020\n",
      "Epoch 16/100\n",
      "6049/6049 [==============================] - 2705s 447ms/step - loss: 2.0130 - accuracy: 0.5341 - val_loss: 2.1982 - val_accuracy: 0.5002\n",
      "加载模型: results/kyu_loss-accuracy_2.1468_0.5048_30001_60000.h5\n",
      "开始训练: 60001 - 110000\n",
      "Epoch 1/100\n",
      "10009/10009 [==============================] - 4517s 451ms/step - loss: 2.2898 - accuracy: 0.4912 - val_loss: 2.1250 - val_accuracy: 0.5105\n",
      "Epoch 2/100\n",
      "10009/10009 [==============================] - 4398s 439ms/step - loss: 2.2412 - accuracy: 0.4978 - val_loss: 2.0983 - val_accuracy: 0.5132\n",
      "Epoch 3/100\n",
      "10009/10009 [==============================] - 4400s 440ms/step - loss: 2.2084 - accuracy: 0.5025 - val_loss: 2.1001 - val_accuracy: 0.5133\n",
      "Epoch 4/100\n",
      "10009/10009 [==============================] - 4398s 439ms/step - loss: 2.1829 - accuracy: 0.5060 - val_loss: 2.0865 - val_accuracy: 0.5149\n",
      "Epoch 5/100\n",
      "10009/10009 [==============================] - 4399s 440ms/step - loss: 2.1622 - accuracy: 0.5090 - val_loss: 2.0823 - val_accuracy: 0.5143\n",
      "Epoch 6/100\n",
      "10009/10009 [==============================] - 4399s 439ms/step - loss: 2.1428 - accuracy: 0.5119 - val_loss: 2.0887 - val_accuracy: 0.5128\n",
      "Epoch 7/100\n",
      "10009/10009 [==============================] - 4399s 439ms/step - loss: 2.1281 - accuracy: 0.5139 - val_loss: 2.0819 - val_accuracy: 0.5157\n",
      "Epoch 8/100\n",
      "10009/10009 [==============================] - 4400s 440ms/step - loss: 2.1116 - accuracy: 0.5163 - val_loss: 2.0886 - val_accuracy: 0.5142\n",
      "Epoch 9/100\n",
      "10009/10009 [==============================] - 4406s 440ms/step - loss: 2.0968 - accuracy: 0.5187 - val_loss: 2.0902 - val_accuracy: 0.5159\n",
      "Epoch 10/100\n",
      "10009/10009 [==============================] - 4409s 440ms/step - loss: 2.0857 - accuracy: 0.5201 - val_loss: 2.0887 - val_accuracy: 0.5155\n",
      "Epoch 11/100\n",
      "10009/10009 [==============================] - 4422s 442ms/step - loss: 2.0727 - accuracy: 0.5222 - val_loss: 2.0840 - val_accuracy: 0.5163\n",
      "Epoch 12/100\n",
      "  101/10009 [..............................] - ETA: 1:11:00 - loss: 2.0524 - accuracy: 0.5259"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15004\\1136954303.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     )\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    452\u001b[0m     \"\"\"\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_supports_tf_logs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m         \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1018\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1020\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1022\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1084\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    508\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     \"\"\"\n\u001b[0;32m   1070\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1071\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1035\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = 1\n",
    "end = 30000\n",
    "batch_size = 1024\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "\n",
    "# 尋找所有文件\n",
    "#saved_models = os.listdir('./results/Kyu/')\n",
    "# 找到具有最低验证损失的模型文件\n",
    "#best_model = min(saved_models, key=lambda x: float(x.split('_')[2]) if x.startswith('kyu_loss-accuracy') else float('inf'))\n",
    "# 构建最佳模型的路径\n",
    "#best_model_path = os.path.join('./results/Kyu/', best_model)\n",
    "#print(\"加载模型:\",best_model_path)\n",
    "# 加载最佳模型的权重\n",
    "#model.load_weights(best_model_path)\n",
    "\n",
    "# 定义 EarlyStopping 回调 :回调参数\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "for i in range(3):\n",
    "    print(\"开始训练:\", start, \"-\", end)\n",
    "\n",
    "    # 定义 ModelCheckpoint 回调 :回调保存\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        f'./results/Kyu/kyu_loss-accuracy_{{val_loss:.4f}}_{{val_accuracy:.4f}}_{start}_{end}.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True)\n",
    "\n",
    "    # 將數據分成訓練和驗證集\n",
    "    games_train, games_val = train_test_split(games[start:end], test_size=0.10,random_state=42)\n",
    "\n",
    "    # 創建數據生成器實例\n",
    "    train_generator = DataGenerator(games_train, batch_size)\n",
    "    val_generator = DataGenerator(games_val, batch_size)\n",
    "\n",
    "\n",
    "\n",
    "    #用数据生成器进行训练\n",
    "    history = model.fit(\n",
    "        x=train_generator,\n",
    "        epochs=100,\n",
    "        validation_data=val_generator,\n",
    "        callbacks=[checkpoint, early_stopping],\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "\n",
    "    # 尋找所有文件\n",
    "    saved_models = os.listdir('./results/Kyu/')\n",
    "    # 找到具有最低验证损失的模型文件\n",
    "    best_model = min(saved_models, key=lambda x: float(x.split('_')[2]) if x.startswith('kyu_loss-accuracy') else float('inf'))\n",
    "    # 构建最佳模型的路径\n",
    "    best_model_path = os.path.join('./results/Kyu/', best_model)\n",
    "    print(\"加载模型:\",best_model_path)\n",
    "    # 加载最佳模型的权重\n",
    "    model.load_weights(best_model_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #將每個 epoch 的值添加到列表中\n",
    "    train_losses.extend(history.history['loss'])\n",
    "    val_losses.extend(history.history['val_loss'])\n",
    "    train_accuracy.extend(history.history['accuracy'])\n",
    "    val_accuracy.extend(history.history['val_accuracy'])\n",
    "\n",
    "\n",
    "    start=start+30000;\n",
    "    end=end+30000;\n",
    "    if (end==90000):\n",
    "        end=110000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 這裡內容為訓練中斷,需要重新讀取權重,繼續訓練"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载模型: results/kyu_loss-accuracy_2.0823_0.5143_60001_110000.h5\n",
      "开始训练: 60001 - 110000\n",
      "Epoch 1/100\n",
      "10009/10009 [==============================] - 4458s 445ms/step - loss: 2.1358 - accuracy: 0.5128 - val_loss: 2.0857 - val_accuracy: 0.5148\n",
      "Epoch 2/100\n",
      "10009/10009 [==============================] - 4427s 442ms/step - loss: 2.1242 - accuracy: 0.5144 - val_loss: 2.0860 - val_accuracy: 0.5162\n",
      "Epoch 3/100\n",
      "10009/10009 [==============================] - 4427s 442ms/step - loss: 2.1082 - accuracy: 0.5171 - val_loss: 2.0816 - val_accuracy: 0.5151\n",
      "Epoch 4/100\n",
      "10009/10009 [==============================] - 4416s 441ms/step - loss: 2.0924 - accuracy: 0.5192 - val_loss: 2.0896 - val_accuracy: 0.5160\n",
      "Epoch 5/100\n",
      "10009/10009 [==============================] - 4442s 444ms/step - loss: 2.0819 - accuracy: 0.5212 - val_loss: 2.0814 - val_accuracy: 0.5153\n",
      "Epoch 6/100\n",
      "10009/10009 [==============================] - 4450s 445ms/step - loss: 2.0662 - accuracy: 0.5234 - val_loss: 2.0833 - val_accuracy: 0.5160\n",
      "Epoch 7/100\n",
      "10009/10009 [==============================] - 4426s 442ms/step - loss: 2.0594 - accuracy: 0.5242 - val_loss: 2.0893 - val_accuracy: 0.5150\n",
      "Epoch 8/100\n",
      "10009/10009 [==============================] - 4425s 442ms/step - loss: 2.0575 - accuracy: 0.5247 - val_loss: 2.0908 - val_accuracy: 0.5151\n",
      "Epoch 9/100\n",
      "10009/10009 [==============================] - 4425s 442ms/step - loss: 1.9818 - accuracy: 0.5361 - val_loss: 2.0496 - val_accuracy: 0.5195\n",
      "Epoch 10/100\n",
      "10009/10009 [==============================] - 4424s 442ms/step - loss: 1.9500 - accuracy: 0.5413 - val_loss: 2.0471 - val_accuracy: 0.5199\n",
      "Epoch 11/100\n",
      "10009/10009 [==============================] - 4422s 442ms/step - loss: 1.9413 - accuracy: 0.5422 - val_loss: 2.0534 - val_accuracy: 0.5192\n",
      "Epoch 12/100\n",
      "10009/10009 [==============================] - 4420s 442ms/step - loss: 1.9350 - accuracy: 0.5435 - val_loss: 2.0558 - val_accuracy: 0.5187\n",
      "Epoch 13/100\n",
      "10009/10009 [==============================] - 4419s 441ms/step - loss: 1.9227 - accuracy: 0.5456 - val_loss: 2.0583 - val_accuracy: 0.5187\n",
      "Epoch 14/100\n",
      " 4940/10009 [=============>................] - ETA: 36:07 - loss: 1.9087 - accuracy: 0.5473"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15988\\1992536466.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m         callbacks=[checkpoint, early_stopping,\n\u001b[0;32m     46\u001b[0m                   ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-7)],\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     )\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "start = 60001\n",
    "end = 110000\n",
    "batch_size = 1024\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "\n",
    "# 尋找所有文件\n",
    "saved_models = os.listdir('./results/Kyu/')\n",
    "# 找到具有最低验证损失的模型文件\n",
    "best_model = min(saved_models, key=lambda x: float(x.split('_')[2]) if x.startswith('kyu_loss-accuracy') else float('inf'))\n",
    "# 构建最佳模型的路径\n",
    "best_model_path = os.path.join('./results/Kyu/', best_model)\n",
    "print(\"加载模型:\",best_model_path)\n",
    "# 加载最佳模型的权重\n",
    "model.load_weights(best_model_path)\n",
    "\n",
    "# 定义 EarlyStopping 回调 :回调参数\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "\n",
    "for i in range(1):\n",
    "    print(\"开始训练:\", start, \"-\", end)\n",
    "\n",
    "    # 定义 ModelCheckpoint 回调 :回调保存\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        f'./results/Kyu/kyu_loss-accuracy_{{val_loss:.4f}}_{{val_accuracy:.4f}}_{start}_{end}.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True)\n",
    "\n",
    "    # 將數據分成訓練和驗證集\n",
    "    games_train, games_val = train_test_split(games[start:end], test_size=0.10,random_state=42)\n",
    "\n",
    "    # 創建數據生成器實例\n",
    "    train_generator = DataGenerator(games_train, batch_size)\n",
    "    val_generator = DataGenerator(games_val, batch_size)\n",
    "\n",
    "\n",
    "\n",
    "    #用数据生成器进行训练\n",
    "    history = model.fit(\n",
    "        x=train_generator,\n",
    "        epochs=100,\n",
    "        validation_data=val_generator,\n",
    "        callbacks=[checkpoint, early_stopping,\n",
    "                  ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-7)],\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "\n",
    "    # 尋找所有文件\n",
    "    saved_models = os.listdir('./results/Kyu/')\n",
    "    # 找到具有最低验证损失的模型文件\n",
    "    best_model = min(saved_models, key=lambda x: float(x.split('_')[2]) if x.startswith('kyu_loss-accuracy') else float('inf'))\n",
    "    # 构建最佳模型的路径\n",
    "    best_model_path = os.path.join('./results/Kyu/', best_model)\n",
    "    print(\"加载模型:\",best_model_path)\n",
    "    # 加载最佳模型的权重\n",
    "    model.load_weights(best_model_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #將每個 epoch 的值添加到列表中\n",
    "    train_losses.extend(history.history['loss'])\n",
    "    val_losses.extend(history.history['val_loss'])\n",
    "    train_accuracy.extend(history.history['accuracy'])\n",
    "    val_accuracy.extend(history.history['val_accuracy'])\n",
    "\n",
    "\n",
    "    start=start+30000;\n",
    "    end=end+30000;\n",
    "    if (end==90000):\n",
    "        end=110000\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
